{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from llama_index.core import StorageContext, load_index_from_storage, QueryBundle\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Load environment variables\n",
    "if os.path.exists(\"../config.env\"):\n",
    "    load_dotenv(\"../config.env\")\n",
    "\n",
    "# Load precomputed document summary embeddings\n",
    "embeddings = np.load(\"../data/processed/lp/summary_embeddings/embeddings.npy\")\n",
    "df = pd.read_csv(\"../data/processed/lp/summary_embeddings/index.tsv\", sep=\"\\t\")\n",
    "embedding_model = OpenAIEmbedding()\n",
    "\n",
    "# LLM setup\n",
    "llm_expansion = ChatOpenAI(temperature=0.0, model=\"gpt-4o\")\n",
    "llm_summary = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo-0125\")\n",
    "llm_rerank = OpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "reranker = LLMRerank(llm=llm_rerank, top_n=3)\n",
    "\n",
    "# Prompt template for query expansion\n",
    "query_expansion_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert in HIV medicine.\"),\n",
    "    (\"user\", (\n",
    "        \"Given the query below, provide a concise, comma-separated list of related terms and synonyms \"\n",
    "        \"useful for document retrieval. Return only the list, no explanations.\\n\\n\"\n",
    "        \"Query: {query}\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "def cosine_similarity_numpy(query_vec: np.ndarray, matrix: np.ndarray) -> np.ndarray:\n",
    "    query_norm = query_vec / np.linalg.norm(query_vec)\n",
    "    matrix_norm = matrix / np.linalg.norm(matrix, axis=1, keepdims=True)\n",
    "    return matrix_norm @ query_norm\n",
    "\n",
    "def expand_query(query):\n",
    "    start = time.time()\n",
    "    messages = query_expansion_prompt.format_messages(query=query)\n",
    "    expanded = llm_expansion.invoke(messages).content.strip()\n",
    "    return expanded, time.time() - start\n",
    "\n",
    "def retrieve(expanded_query):\n",
    "    start = time.time()\n",
    "    query_vec = embedding_model.get_text_embedding(expanded_query)\n",
    "    sims = cosine_similarity_numpy(query_vec, embeddings)\n",
    "    top_paths = df.loc[sims.argsort()[-3:][::-1], \"vectorestore_path\"].tolist()\n",
    "    top_paths = [\n",
    "        os.path.join(\"..\", p)\n",
    "        for p in df.loc[sims.argsort()[-3:][::-1], \"vectorestore_path\"].tolist()\n",
    "    ]\n",
    "    \n",
    "    all_nodes = []\n",
    "    for path in top_paths:\n",
    "        ctx = StorageContext.from_defaults(persist_dir=path)\n",
    "        index = load_index_from_storage(ctx)\n",
    "        retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
    "        all_nodes.extend(retriever.retrieve(expanded_query))\n",
    "\n",
    "    return all_nodes, top_paths, time.time() - start\n",
    "\n",
    "# def rerank(expanded_query, nodes):\n",
    "#     start = time.time()\n",
    "#     bundle = QueryBundle(expanded_query)\n",
    "#     reranked = reranker.postprocess_nodes(nodes, bundle)\n",
    "#     return reranked, time.time() - start\n",
    "\n",
    "# def rerank(expanded_query, nodes):\n",
    "#     start = time.time()\n",
    "    \n",
    "#     # Embed the expanded query\n",
    "#     query_vec = embedding_model.get_text_embedding(expanded_query)\n",
    "    \n",
    "#     # Embed each node’s text\n",
    "#     texts = [n.text for n in nodes]\n",
    "#     node_vecs = embedding_model.get_text_embedding_batch(texts)\n",
    "    \n",
    "#     # Compute cosine similarities\n",
    "#     sims = cosine_similarity_numpy(query_vec, np.array(node_vecs))\n",
    "#     top_idxs = sims.argsort()[-2:][::-1]  # top 2 most similar\n",
    "    \n",
    "#     # Select top nodes\n",
    "#     reranked = [nodes[i] for i in top_idxs]\n",
    "#     return reranked, time.time() - start\n",
    "\n",
    "def rerank(expanded_query, nodes, embedder, llm_reranker, top_n_cosine=5, top_n_llm=2):\n",
    "    \"\"\"\n",
    "    Hybrid reranker:\n",
    "    1. Use cosine similarity to pre-filter top_n_cosine nodes.\n",
    "    2. Use LLM reranker to select top_n_llm from those.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Embed query and candidate nodes\n",
    "    query_vec = embedder.get_text_embedding(expanded_query)\n",
    "    texts = [n.text for n in nodes]\n",
    "    node_vecs = embedder.get_text_embedding_batch(texts)\n",
    "\n",
    "    # Cosine similarity ranking\n",
    "    sims = cosine_similarity_numpy(query_vec, np.array(node_vecs))\n",
    "    top_cosine_idxs = sims.argsort()[-top_n_cosine:][::-1]\n",
    "    prefiltered_nodes = [nodes[i] for i in top_cosine_idxs]\n",
    "\n",
    "    # LLM reranking\n",
    "    bundle = QueryBundle(expanded_query)\n",
    "    final_nodes = llm_reranker.postprocess_nodes(prefiltered_nodes, bundle)[0:top_n_llm]\n",
    "\n",
    "    return final_nodes, time.time() - start\n",
    "\n",
    "\n",
    "def summarize(query, contexts):\n",
    "    start = time.time()\n",
    "    prompt = (\n",
    "        \"You're a clinical assistant helping a provider answer a question using HIV/AIDS guidelines.\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        \"Provide a detailed summary of the most relevant points from the following source texts using bullet points.\\n\\n\"\n",
    "        + \"\\n\\n\".join([f\"Source {i+1}: {text}\" for i, text in enumerate(contexts)])\n",
    "    )\n",
    "    input_tokens = count_tokens(prompt)\n",
    "    result = llm_summary.invoke(prompt).content.strip()\n",
    "    elapsed = time.time() - start\n",
    "    return result, elapsed, input_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fafb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example question list (replace/expand as needed)\n",
    "queries = [\n",
    "    \"What are important drug interactions with dolutegravir?\",\n",
    "    \"How should PrEP be provided to adolescent girls?\",\n",
    "    \"When is cotrimoxazole prophylaxis indicated?\",\n",
    "    \"What are the guidelines for ART failure?\",\n",
    "    \"How do you manage HIV in pregnancy?\",\n",
    "    \"When should infants start ART?\",\n",
    "    \"What is the recommended PrEP regimen for men who have sex with men?\",\n",
    "    \"How often should viral load be monitored?\",\n",
    "    \"What is the preferred first-line regimen for adults?\",\n",
    "    \"Can pregnant women use dolutegravir?\",\n",
    "    \"When is tenofovir not recommended?\",\n",
    "    \"How should HIV be managed in tuberculosis coinfection?\",\n",
    "    \"What lab tests are used to monitor ART?\",\n",
    "    \"When is second-line ART initiated?\",\n",
    "    \"What adherence strategies are recommended?\",\n",
    "    \"What are the contraindications to efavirenz?\",\n",
    "    \"Can HIV be managed with a two-drug regimen?\",\n",
    "    \"How do you handle treatment failure?\",\n",
    "    \"When is regimen switching appropriate?\",\n",
    "    \"What is the role of resistance testing?\"\n",
    "]\n",
    "\n",
    "timing_results = []\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\n⏳ {q}\")\n",
    "\n",
    "    expanded, t_expand = expand_query(q)\n",
    "    nodes, top_paths, t_retrieve = retrieve(expanded)\n",
    "    # reranked_nodes, t_rerank = rerank(expanded, nodes)\n",
    "    reranked_nodes, t_rerank = rerank(\n",
    "        expanded_query=expanded,\n",
    "        nodes=nodes,\n",
    "        embedder=embedding_model,\n",
    "        llm_reranker=reranker,\n",
    "        top_n_cosine=5,\n",
    "        top_n_llm=2\n",
    "    )\n",
    "    answer, t_summarize, token_count = summarize(q, [n.text for n in reranked_nodes])\n",
    "\n",
    "\n",
    "    timing_results.append({\n",
    "        \"question\": q,\n",
    "        \"expand_time\": round(t_expand, 2),\n",
    "        \"retrieve_time\": round(t_retrieve, 2),\n",
    "        \"rerank_time\": round(t_rerank, 2),\n",
    "        \"summarize_time\": round(t_summarize, 2),\n",
    "        \"input_tokens_to_summarizer\": token_count,\n",
    "        \"total_time\": round(t_expand + t_retrieve + t_rerank + t_summarize, 2)\n",
    "    })\n",
    "\n",
    "\n",
    "# Save results\n",
    "df = pd.DataFrame(timing_results)\n",
    "df.to_csv(\"timing_benchmark_with_rerank_gpt35_hybridrerank.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Done. Timing results saved to timing_benchmark_with_rerank.csv\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinician-assistant-lg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
